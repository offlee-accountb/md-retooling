#!/usr/bin/env python3
"""
Smart Injector v3 - í†µí•© HWPX ë°ì´í„° ì£¼ì… ë„êµ¬

=== ëª…ë ¹ì–´ ===

1. analyze: HWPX ë¶„ì„ â†’ í”„ë¡¬í”„íŠ¸ + ë¹ˆ í…œí”Œë¦¿ ìƒì„±
   python smart_injector.py analyze input.hwpx -o prefix
   
2. parse: ì‚¬ìš©ì ì‘ë‹µ â†’ YAML ë³€í™˜
   python smart_injector.py parse response.txt -o fields.yaml
   
3. inject: HWPX + YAML â†’ ì™„ì„± ë¬¸ì„œ
   python smart_injector.py inject input.hwpx fields.yaml -o output.hwpx
   
4. full: ì „ì²´ íŒŒì´í”„ë¼ì¸ (analyze + ëŒ€ê¸° + inject)
   python smart_injector.py full input.hwpx -o output.hwpx

=== 2ë‹¨ê³„ ê·œì¹™ ì‹œìŠ¤í…œ ===

1ë‹¨ê³„ (ìë™ ê°ì§€):
   - ë¼ë²¨ ì°¾ê¸° â†’ ì˜† ì…€ ì¡´ì¬ + ë¹„ì–´ìˆìŒ â†’ ì˜† ì…€ì— ì‘ì„±
   - ë¼ë²¨ ì°¾ê¸° â†’ ì˜† ì…€ ì—†ê±°ë‚˜ ë‚´ìš© ìˆìŒ â†’ ì½œë¡  ë’¤ì— append

2ë‹¨ê³„ (ëª…ì‹œì  ì§€ì •):
   - YAMLì—ì„œ modeë¥¼ ëª…ì‹œí•˜ë©´ ê·¸ ê·œì¹™ ìš°ì„ 
   - mode: next_cell | append | replace | prepend | skip_colon
"""

import argparse
import zipfile
import tempfile
import os
import re
import yaml
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime


# XML ë„¤ì„ìŠ¤í˜ì´ìŠ¤
HP_NS = '{http://www.hancom.co.kr/hwpml/2011/paragraph}'
HS_NS = '{http://www.hancom.co.kr/hwpml/2011/section}'
HC_NS = '{http://www.hancom.co.kr/hwpml/2011/core}'

NAMESPACES = {
    'hp': 'http://www.hancom.co.kr/hwpml/2011/paragraph',
    'hs': 'http://www.hancom.co.kr/hwpml/2011/section',
    'hc': 'http://www.hancom.co.kr/hwpml/2011/core',
}

for prefix, uri in NAMESPACES.items():
    ET.register_namespace(prefix, uri)


# ==============================================================================
# Phase 1: ë¼ë²¨ ì •ê·œí™” ë° í”Œë ˆì´ìŠ¤í™€ë” ì¸ì‹
# ==============================================================================

# ==============================================================================
# Phase 2: ë¼ë²¨ ë³„ì¹­ DB (ë™ì˜ì–´ ë§¤í•‘)
# ==============================================================================

# ì •ê·œí™”ëœ ëŒ€í‘œ ë¼ë²¨ â†’ [ë³„ì¹­ ë¦¬ìŠ¤íŠ¸]
# ê²€ìƒ‰ ì‹œ: YAML ë¼ë²¨ì˜ ë³„ì¹­ë“¤ë„ í•¨ê»˜ ê²€ìƒ‰
LABEL_ALIASES = {
    # ê¸°ì—… ê´€ë ¨
    "ê¸°ì—…ëª…": ["ê¸°ì—…ì²´ëª…", "íšŒì‚¬ëª…", "ìƒí˜¸", "ë²•ì¸ëª…", "ì—…ì²´ëª…"],
    "ëŒ€í‘œì": ["ëŒ€í‘œì´ì‚¬", "ëŒ€í‘œìëª…", "ëŒ€í‘œ", "ëŒ€í‘œìë˜ëŠ”ëŒ€í‘œì´ì‚¬", "ëŒ€í‘œìë˜ëŠ”ëŒ€í‘œì´ì‚¬(ë³¸ì¸)"],
    "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸": ["ì‚¬ì—…ìë²ˆí˜¸", "ì‚¬ì—…ìë“±ë¡", "ë“±ë¡ë²ˆí˜¸", "ì‚¬ì—…ìë²ˆí˜¸ë˜ëŠ”ë²•ì¸ë²ˆí˜¸"],
    
    # ë‹´ë‹¹ì ê´€ë ¨  
    "ì„±ëª…": ["ì´ë¦„", "ë‹´ë‹¹ìëª…", "ë‹´ë‹¹ì", "ì‘ì„±ì"],
    "ë¶€ì„œëª…": ["ë¶€ì„œ", "ì†Œì†ë¶€ì„œ", "ì†Œì†"],
    "ì§ìœ„": ["ì§ì±…", "ì§ê¸‰"],
    
    # ì—°ë½ì²˜ ê´€ë ¨
    "íœ´ëŒ€í°": ["íœ´ëŒ€ì „í™”", "í•¸ë“œí°", "ëª¨ë°”ì¼", "H.P", "HP"],
    "ì „í™”": ["ì „í™”ë²ˆí˜¸", "ìœ ì„ ì „í™”", "TEL"],
    "ì´ë©”ì¼": ["E-mail", "email", "ë©”ì¼", "ì´ë©”ì¼ì£¼ì†Œ"],
    "ì—°ë½ì²˜": ["ì „í™”", "ì „í™”ë²ˆí˜¸", "ì—°ë½ì²˜"],
    
    # ì£¼ì†Œ ê´€ë ¨
    "ì£¼ì†Œ": ["ì†Œì¬ì§€", "ì‚¬ì—…ì¥ì£¼ì†Œ", "ë³¸ì‚¬ì£¼ì†Œ", "íšŒì‚¬ì£¼ì†Œ"],
    
    # ì‹ ì²­ ê´€ë ¨
    "ì‹ ì²­ê¸°ì—…ëª…": ["ì‹ ì²­ê¸°ì—…", "ì‹ ì²­ì—…ì²´ëª…", "ì‹ ì²­íšŒì‚¬ëª…"],
    "ì‹ ì²­ì": ["ì‹ ì²­ì¸", "ì‹ ì²­ìëª…"],
    "ì‹ ì²­ì¼": ["ì‹ ì²­ì¼ì", "ì ‘ìˆ˜ì¼", "ì ‘ìˆ˜ì¼ì"],
    
    # ì„¤ë¦½ ê´€ë ¨
    "ì„¤ë¦½ì¼ì": ["ì„¤ë¦½ì¼", "ì°½ì—…ì¼", "ì°½ì—…ì¼ì", "ê°œì—…ì¼"],
    
    # ìˆ˜ì‹ ì ê´€ë ¨
    "ê·€ì¤‘": ["ê·€í•˜", "ì•"],
}

# ì—­ë°©í–¥ ë§¤í•‘ ìƒì„± (ë³„ì¹­ â†’ ëŒ€í‘œ ë¼ë²¨)
ALIAS_TO_CANONICAL = {}
for canonical, aliases in LABEL_ALIASES.items():
    ALIAS_TO_CANONICAL[canonical] = canonical
    for alias in aliases:
        ALIAS_TO_CANONICAL[alias] = canonical

def get_label_variants(label: str) -> List[str]:
    """ë¼ë²¨ì˜ ëª¨ë“  ë³€í˜• ë°˜í™˜ (ìì‹  + ë³„ì¹­ë“¤)
    
    Examples:
        "ê¸°ì—…ëª…" â†’ ["ê¸°ì—…ëª…", "ê¸°ì—…ì²´ëª…", "íšŒì‚¬ëª…", "ìƒí˜¸", "ë²•ì¸ëª…", "ì—…ì²´ëª…"]
        "unknown" â†’ ["unknown"]
    """
    normalized = normalize_label(label).replace(':', '').strip()
    
    # ëŒ€í‘œ ë¼ë²¨ì´ë©´ ìì‹  + ë³„ì¹­ë“¤
    if normalized in LABEL_ALIASES:
        return [normalized] + LABEL_ALIASES[normalized]
    
    # ë³„ì¹­ì´ë©´ ëŒ€í‘œ ë¼ë²¨ + ëª¨ë“  ë³„ì¹­ë“¤
    if normalized in ALIAS_TO_CANONICAL:
        canonical = ALIAS_TO_CANONICAL[normalized]
        return [canonical] + LABEL_ALIASES.get(canonical, [])
    
    # ë¯¸ë“±ë¡ ë¼ë²¨
    return [normalized]

def normalize_label(text: str) -> str:
    """í•œêµ­ ê³µë¬¸ì„œ ë¼ë²¨ ì •ê·œí™”
    
    ì²˜ë¦¬:
    1. ì—°ì† ê³µë°± â†’ ë‹¨ì¼ ê³µë°±
    2. í•œê¸€ ìê°„ ê³µë°± ì œê±° (ì‹   ì²­  ì â†’ ì‹ ì²­ì)
    3. ì½œë¡  ì •ê·œí™” (ï¼šâ†’ :)
    4. ì ‘ë¯¸ì‚¬ ì œê±° ((ì¸), (ì„œëª…) ë“±)
    
    Examples:
        "ì‹   ì²­  ì :" â†’ "ì‹ ì²­ì:"
        "ê¸° ì—… ì²´ ëª…" â†’ "ê¸°ì—…ì²´ëª…"
        "ëŒ€í‘œì    (ì¸)" â†’ "ëŒ€í‘œì"
    """
    if not text:
        return ""
    
    # 1. ì „ê° ì½œë¡  â†’ ë°˜ê° ì½œë¡ 
    text = text.replace('ï¼š', ':')
    
    # 2. í•œê¸€ ìê°„ ê³µë°± ì œê±° (í•œê¸€ ë¬¸ì ì‚¬ì´ì˜ ê³µë°±)
    # ì˜ˆ: "ì‹   ì²­  ì" â†’ "ì‹ ì²­ì"
    text = re.sub(r'([ê°€-í£])\s+([ê°€-í£])', r'\1\2', text)
    # ë°˜ë³µ ì ìš© (3ê¸€ì ì´ìƒì˜ ê²½ìš°)
    text = re.sub(r'([ê°€-í£])\s+([ê°€-í£])', r'\1\2', text)
    text = re.sub(r'([ê°€-í£])\s+([ê°€-í£])', r'\1\2', text)
    
    # 3. ì—°ì† ê³µë°± â†’ ë‹¨ì¼ ê³µë°±
    text = re.sub(r'\s+', ' ', text)
    
    # 4. ì ‘ë¯¸ì‚¬ ì œê±° (ì¸), (ì„œëª…), (ë‚ ì¸), (ì§ì¸)
    text = re.sub(r'\s*\([ì¸ì„œëª…ë‚ ì§]\w*\)\s*$', '', text)
    
    # 5. ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()
    
    return text


# í”Œë ˆì´ìŠ¤í™€ë” íŒ¨í„´ (ë¹ˆ ê°’ìœ¼ë¡œ ì¸ì‹í•´ì•¼ í•  ê²ƒë“¤)
PLACEHOLDER_PATTERNS = [
    r'^[ã…‡â—‹â—¯]{2,}$',                    # ã…‡ã…‡ã…‡, â—‹â—‹â—‹
    r'^[_\-]{3,}$',                      # ___, ---
    r'^\s*$',                            # ë¹ˆ ê°’
    r'^\([ì¸ì„œëª…ë‚ ì§]\w*\)$',            # (ì¸), (ì„œëª…), (ë‚ ì¸), (ì§ì¸)
    r'^\(ë²•ì¸\s*ì„œëª…\)$',                # (ë²•ì¸ ì„œëª…)
    r'^\(ê°œì¸\s*ì„œëª…\)$',                # (ê°œì¸ ì„œëª…)
    r'^\d{2,4}\s*ë…„\s*ì›”\s*ì¼$',         # 20  ë…„  ì›”  ì¼, 2025ë…„ ì›” ì¼
    r'^ë…„\s*ì›”\s*ì¼$',                   # ë…„  ì›”  ì¼
]

def is_placeholder(text: str) -> bool:
    """ê°’ì´ í”Œë ˆì´ìŠ¤í™€ë”ì¸ì§€ í™•ì¸
    
    í”Œë ˆì´ìŠ¤í™€ë” = ì‹¤ì œ ë°ì´í„°ê°€ ì•„ë‹Œ ìë¦¬ í‘œì‹œì
    
    Examples:
        "ã…‡ã…‡ã…‡" â†’ True
        "(ì¸)" â†’ True  
        "20  ë…„  ì›”  ì¼" â†’ True
        "í™ê¸¸ë™" â†’ False
    """
    if not text:
        return True
    
    text = text.strip()
    if not text:
        return True
    
    # íŒ¨í„´ ë§¤ì¹­
    for pattern in PLACEHOLDER_PATTERNS:
        if re.match(pattern, text, re.IGNORECASE):
            return True
    
    return False


# ==============================================================================
# Phase 2: ë‚ ì§œ íŒ¨í„´ ì¸ì‹
# ==============================================================================

# ë‚ ì§œ í”Œë ˆì´ìŠ¤í™€ë” íŒ¨í„´ë“¤
DATE_PLACEHOLDER_PATTERNS = [
    # "2025ë…„   ì›”   ì¼" - ì—°ë„ë§Œ ìˆê³  ì›”ì¼ì´ ë¹„ì–´ìˆìŒ
    r'^(\d{4})\s*ë…„\s+ì›”\s+ì¼\s*$',
    # "20  ë…„  ì›”  ì¼" - ì—°ë„ ì• ë‘ìë¦¬ë§Œ ìˆìŒ
    r'^(\d{2})\s+ë…„\s+ì›”\s+ì¼\s*$',
    # "ë…„  ì›”  ì¼" - ì „ë¶€ ë¹„ì–´ìˆìŒ
    r'^ë…„\s+ì›”\s+ì¼\s*$',
]

def is_date_placeholder(text: str) -> bool:
    """ë‚ ì§œ í”Œë ˆì´ìŠ¤í™€ë”ì¸ì§€ í™•ì¸
    
    Examples:
        "2025ë…„   ì›”   ì¼" â†’ True
        "20  ë…„  ì›”  ì¼" â†’ True
        "ë…„  ì›”  ì¼" â†’ True
        "2025ë…„ 11ì›” 30ì¼" â†’ False (ì™„ì„±ëœ ë‚ ì§œ)
    """
    if not text:
        return False
    
    text = text.strip()
    for pattern in DATE_PLACEHOLDER_PATTERNS:
        if re.match(pattern, text):
            return True
    return False


def format_current_date(template: str = None) -> str:
    """í˜„ì¬ ë‚ ì§œë¥¼ í•œêµ­ì‹ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    
    Args:
        template: ë‚ ì§œ í…œí”Œë¦¿ (Noneì´ë©´ ê¸°ë³¸ í˜•ì‹)
        
    Returns:
        "2025ë…„ 11ì›” 30ì¼" í˜•ì‹
    """
    now = datetime.now()
    return f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼"


def fill_date_placeholder(text: str) -> str:
    """ë‚ ì§œ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ í˜„ì¬ ë‚ ì§œë¡œ ì±„ì›€
    
    Examples:
        "2025ë…„   ì›”   ì¼" â†’ "2025ë…„ 11ì›” 30ì¼"
        "20  ë…„  ì›”  ì¼" â†’ "2025ë…„ 11ì›” 30ì¼"
    """
    now = datetime.now()
    
    # íŒ¨í„´ 1: ì—°ë„ ìˆìŒ
    match = re.match(r'^(\d{4})\s*ë…„\s+ì›”\s+ì¼\s*$', text.strip())
    if match:
        year = int(match.group(1))
        return f"{year}ë…„ {now.month}ì›” {now.day}ì¼"
    
    # íŒ¨í„´ 2: ì—°ë„ ì• ë‘ìë¦¬
    match = re.match(r'^(\d{2})\s+ë…„\s+ì›”\s+ì¼\s*$', text.strip())
    if match:
        year_prefix = match.group(1)
        # 20XX í˜•íƒœë¡œ ê°€ì •
        year = int(f"20{year_prefix[-1]}{now.year % 10}" if len(year_prefix) == 2 else f"{year_prefix}{now.year % 100}")
        return f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼"
    
    # íŒ¨í„´ 3: ì „ë¶€ ë¹„ì–´ìˆìŒ
    if re.match(r'^ë…„\s+ì›”\s+ì¼\s*$', text.strip()):
        return f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼"
    
    return text


# ==============================================================================
# Phase 2: ì„œëª…ë€ íŒ¨í„´ ì¸ì‹
# ==============================================================================

# ì„œëª…ë€ íŒ¨í„´: "ë¼ë²¨ : í”Œë ˆì´ìŠ¤í™€ë” (ì¸/ì„œëª…)"
# ì˜ˆ: "ì‹   ì²­  ì :             (ì¸)"
#     "ê¸°ì—…ëª… :     ã…‡ã…‡ã…‡  (ì¸)"
#     "ëŒ€í‘œì :     ã…‡ã…‡ã…‡  (ì¸)"

SIGNATURE_SUFFIXES = ['(ì¸)', '(å°)', '(ì„œëª…)', '(ë‚ ì¸)', '(ì§ì¸)', 
                      '(ë²•ì¸ ì„œëª…)', '(ê°œì¸ ì„œëª…)', '(ë²•ì¸ì„œëª…)', '(ê°œì¸ì„œëª…)']

def parse_signature_line(text: str) -> Optional[dict]:
    """ì„œëª…ë€ íŒ¨í„´ì—ì„œ ë¼ë²¨ ì¶”ì¶œ
    
    Examples:
        "ì‹   ì²­  ì :             (ì¸)" â†’ {"label": "ì‹ ì²­ì", "suffix": "(ì¸)"}
        "ê¸°ì—…ëª… :     ã…‡ã…‡ã…‡  (ì¸)" â†’ {"label": "ê¸°ì—…ëª…", "suffix": "(ì¸)"}
        
    Returns:
        {"label": ì •ê·œí™”ëœ ë¼ë²¨, "suffix": ì„œëª… ì ‘ë¯¸ì‚¬} ë˜ëŠ” None
    """
    if not text:
        return None
    
    text = text.strip()
    
    # ì„œëª… ì ‘ë¯¸ì‚¬ í™•ì¸
    suffix_found = None
    for suffix in SIGNATURE_SUFFIXES:
        if text.endswith(suffix):
            suffix_found = suffix
            text = text[:-len(suffix)].strip()
            break
    
    if not suffix_found:
        return None
    
    # í”Œë ˆì´ìŠ¤í™€ë” ì œê±° (ã…‡ã…‡ã…‡ ë“±)
    text = re.sub(r'[ã…‡â—‹â—¯]+', '', text).strip()
    
    # ì½œë¡ ìœ¼ë¡œ ë¶„ë¦¬
    if ':' in text:
        parts = text.split(':')
        label = parts[0].strip()
    elif 'ï¼š' in text:
        parts = text.split('ï¼š')
        label = parts[0].strip()
    else:
        label = text
    
    # ë¼ë²¨ ì •ê·œí™”
    label = normalize_label(label)
    
    if not label:
        return None
    
    return {"label": label, "suffix": suffix_found}


def calc_similarity(s1: str, s2: str) -> float:
    """ë‘ ë¬¸ìì—´ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)
    
    ê°„ë‹¨í•œ ë°©ì‹: ê³µí†µ ë¬¸ì ë¹„ìœ¨
    """
    if not s1 or not s2:
        return 0.0
    
    # ì •ê·œí™”
    n1 = normalize_label(s1).replace(':', '').replace(' ', '').lower()
    n2 = normalize_label(s2).replace(':', '').replace(' ', '').lower()
    
    if not n1 or not n2:
        return 0.0
    
    if n1 == n2:
        return 1.0
    
    # í¬í•¨ ê´€ê³„
    if n1 in n2:
        return len(n1) / len(n2)
    if n2 in n1:
        return len(n2) / len(n1)
    
    # ê³µí†µ ë¬¸ì ìˆ˜
    common = sum(1 for c in n1 if c in n2)
    return common / max(len(n1), len(n2))


class InjectionMode(Enum):
    """ì£¼ì… ëª¨ë“œ"""
    AUTO = "auto"           # ìë™ ê°ì§€ (ê¸°ë³¸ê°’)
    NEXT_CELL = "next_cell" # ë‹¤ìŒ ì…€ì— ì‘ì„±
    APPEND = "append"       # ë¼ë²¨ ë’¤ì— ë¶™ì´ê¸°
    REPLACE = "replace"     # ë¼ë²¨ ì „ì²´ êµì²´
    SKIP_COLON = "skip_colon"  # [ë¼ë²¨] | [:] | [ê°’] íŒ¨í„´ - 2ì¹¸ ë’¤ì— ì£¼ì…
    PREPEND = "prepend"     # [_____ ë¼ë²¨] íŒ¨í„´ - ë¼ë²¨ ì• ë°‘ì¤„ì— ì£¼ì…


@dataclass
class FieldSpec:
    """í•„ë“œ ì£¼ì… ëª…ì„¸"""
    label: str              # ì°¾ì„ ë¼ë²¨
    value: str              # ì£¼ì…í•  ê°’
    mode: InjectionMode = InjectionMode.AUTO  # ì£¼ì… ëª¨ë“œ
    
    @classmethod
    def from_dict(cls, d: dict) -> 'FieldSpec':
        mode_str = d.get('mode', 'auto')
        try:
            mode = InjectionMode(mode_str)
        except ValueError:
            mode = InjectionMode.AUTO
        return cls(
            label=d['label'],
            value=str(d['value']),
            mode=mode
        )


@dataclass
class InjectionConfig:
    """ì£¼ì… ì„¤ì •"""
    fields: List[FieldSpec] = field(default_factory=list)
    keywords: Dict[str, str] = field(default_factory=dict)  # (í‚¤ì›Œë“œ) íŒ¨í„´
    tables: Dict[str, List[List[str]]] = field(default_factory=dict)
    title: Optional[str] = None


def parse_yaml_config(yaml_path: str) -> InjectionConfig:
    """YAML ì„¤ì • íŒŒì¼ íŒŒì‹±"""
    with open(yaml_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    result = InjectionConfig()
    
    if not config:
        return result
    
    result.title = config.get('title')
    result.keywords = config.get('keywords', {})
    result.tables = config.get('tables', {})
    
    # fields íŒŒì‹± (ìƒˆë¡œìš´ í˜•ì‹)
    for field_dict in config.get('fields', []):
        result.fields.append(FieldSpec.from_dict(field_dict))
    
    # í•˜ìœ„ í˜¸í™˜ì„±: labels, cells â†’ fieldsë¡œ ë³€í™˜
    for label, value in config.get('labels', {}).items():
        result.fields.append(FieldSpec(label=label, value=value, mode=InjectionMode.APPEND))
    
    for label, value in config.get('cells', {}).items():
        result.fields.append(FieldSpec(label=label, value=value, mode=InjectionMode.NEXT_CELL))
    
    return result


class SmartInjector:
    """ìŠ¤ë§ˆíŠ¸ ì¸ì í„° v3 - ì •ê·œí™” + colSpan ì¸ì‹"""
    
    def __init__(self, xml_content: str):
        self.original_xml = xml_content
        self.root = ET.fromstring(xml_content)
        self.injection_log = []  # ì£¼ì… ë¡œê·¸
    
    def log(self, message: str):
        """ë¡œê·¸ ê¸°ë¡"""
        self.injection_log.append(message)
        print(f"  {message}")
    
    def get_cell_text(self, tc) -> str:
        """ì…€ì˜ ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return ''.join(t.text or '' for t in tc.iter(f'{HP_NS}t'))
    
    def get_cell_span(self, tc) -> dict:
        """ì…€ì˜ ë³‘í•© ì •ë³´ ì¶”ì¶œ"""
        cell_span = tc.find(f'{HP_NS}cellSpan')
        if cell_span is not None:
            return {
                'col': int(cell_span.get('colSpan', 1)),
                'row': int(cell_span.get('rowSpan', 1))
            }
        return {'col': 1, 'row': 1}
    
    def is_cell_empty(self, tc) -> bool:
        """ì…€ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸ (í”Œë ˆì´ìŠ¤í™€ë”ë„ ë¹ˆ ê²ƒìœ¼ë¡œ ì·¨ê¸‰)"""
        texts = list(tc.iter(f'{HP_NS}t'))
        if not texts:
            return True
        
        cell_text = ''.join((t.text or '') for t in texts).strip()
        
        # ë¹ˆ ë¬¸ìì—´
        if not cell_text:
            return True
        
        # í”Œë ˆì´ìŠ¤í™€ë” ì²´í¬
        if is_placeholder(cell_text):
            return True
        
        return False
    
    def inject_to_cell(self, tc, value: str) -> bool:
        """ì…€ì— ê°’ ì£¼ì…"""
        # ê¸°ì¡´ hp:t ìš”ì†Œ ì°¾ê¸°
        texts = list(tc.iter(f'{HP_NS}t'))
        
        if texts:
            # ì²« ë²ˆì§¸ ë¹ˆ hp:tì— ê°’ ì„¤ì •
            for t in texts:
                if (t.text or '').strip() == '' or is_placeholder((t.text or '')):
                    t.text = value
                    return True
            # ëª¨ë“  hp:tê°€ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ì²« ë²ˆì§¸ì— ì¶”ê°€
            texts[0].text = (texts[0].text or '') + value
            return True
        else:
            # hp:tê°€ ì—†ìœ¼ë©´ hp:run ì•ˆì— ìƒì„±
            runs = list(tc.iter(f'{HP_NS}run'))
            if runs:
                t_elem = ET.SubElement(runs[0], f'{HP_NS}t')
                t_elem.text = value
                return True
        return False
    
    def detect_injection_mode(self, label: str, tc, row_cells: list, cell_idx: int) -> InjectionMode:
        """ìë™ ê°ì§€: ë‹¤ìŒ ì…€ ì¡´ì¬ ì—¬ë¶€ ê¸°ë°˜
        
        ê·œì¹™ (HWPX í…Œì´ë¸” ë¶„ì„ ê²°ê³¼):
        1. ë¼ë²¨ ì•ì— ê³µë°± runì´ ìˆìŒ â†’ PREPEND (ë°‘ì¤„ ì˜ì—­ì— ê°’)
        2. ë‹¤ìŒ ì…€ì´ ì¡´ì¬í•˜ê³  ë¹„ì–´ìˆìŒ â†’ NEXT_CELL (ê°’ì„ ë‹¤ìŒ ì…€ì—)
        3. ë‹¤ìŒ ì…€ì´ ':'ë§Œ ìˆê³ , ê·¸ ë‹¤ìŒ ì…€ì´ ë¹„ì–´ìˆìŒ â†’ SKIP_COLON (2ì¹¸ ë’¤ì—)
        4. ë‹¤ìŒ ì…€ì´ ì—†ê±°ë‚˜ ë‚´ìš©ì´ ìˆìŒ â†’ APPEND (ë¼ë²¨ ë’¤ì— ë¶™ì´ê¸°)
        
        â€» colSpanì€ ë¼ë²¨ ì…€ì˜ í¬ê¸°ì¼ ë¿, ê°’ ìœ„ì¹˜ì™€ ë¬´ê´€í•¨
           ì˜ˆ: "ëŒ€í‘œì"(colSpan=2) ì˜†ì— ë¹ˆ ì…€(colSpan=2) â†’ NEXT_CELL
           ì˜ˆ: [ê¸° ì—… ì²´ ëª…] | [:] | [ë¹ˆì¹¸] â†’ SKIP_COLON (2ì¹¸ ë’¤ì— ê°’)
           ì˜ˆ: [___ ê·€ì¤‘] â†’ PREPEND (ë°‘ì¤„ ìë¦¬ì— ê°’)
        """
        # 1. PREPEND íŒ¨í„´ ê°ì§€: ì…€ ë‚´ì—ì„œ ë¼ë²¨ ì•ì— ê³µë°± runì´ ìˆëŠ”ì§€
        runs = list(tc.iter(f'{HP_NS}run'))
        if len(runs) >= 2:
            # ë¼ë²¨ì´ í¬í•¨ëœ run ì°¾ê¸°
            label_run_idx = -1
            norm_label = normalize_label(label)
            for i, run in enumerate(runs):
                t = run.find(f'{HP_NS}t')
                if t is not None and t.text:
                    if norm_label in normalize_label(t.text):
                        label_run_idx = i
                        break
            
            # ë¼ë²¨ run ì•ì— ê³µë°±ë§Œ ìˆëŠ” runì´ ìˆìœ¼ë©´ PREPEND
            if label_run_idx > 0:
                prev_run = runs[label_run_idx - 1]
                prev_t = prev_run.find(f'{HP_NS}t')
                if prev_t is not None and prev_t.text:
                    # ê³µë°±ë§Œ ìˆê³  ìµœì†Œ 5ì ì´ìƒì´ë©´ ë°‘ì¤„ ì˜ì—­ìœ¼ë¡œ íŒë‹¨
                    if prev_t.text.strip() == '' and len(prev_t.text) >= 5:
                        return InjectionMode.PREPEND
        
        # 2. ë‹¤ìŒ ì…€ í™•ì¸
        has_next_empty_cell = False
        skip_colon_pattern = False
        
        if cell_idx + 1 < len(row_cells):
            next_tc = row_cells[cell_idx + 1]
            next_text = self.get_cell_text(next_tc).strip()
            
            # ë‹¤ìŒ ì…€ì´ ì½œë¡ ë§Œ ìˆëŠ” ê²½ìš° (: ë˜ëŠ” ï¼š)
            if next_text in [':', 'ï¼š']:
                # ê·¸ ë‹¤ìŒ ì…€(2ì¹¸ ë’¤)ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                if cell_idx + 2 < len(row_cells):
                    next_next_tc = row_cells[cell_idx + 2]
                    if self.is_cell_empty(next_next_tc):
                        skip_colon_pattern = True
            elif self.is_cell_empty(next_tc):
                has_next_empty_cell = True
        
        if skip_colon_pattern:
            return InjectionMode.SKIP_COLON
        elif has_next_empty_cell:
            return InjectionMode.NEXT_CELL
        else:
            return InjectionMode.APPEND
    
    def match_label(self, search_label: str, cell_text: str, threshold: float = 0.8) -> bool:
        """ë¼ë²¨ ë§¤ì¹­ (ì •ê·œí™” + ë³„ì¹­ DB + í¼ì§€ ë§¤ì¹­ + ì„œëª…ë€ ì¸ì‹)
        
        Args:
            search_label: ì°¾ìœ¼ë ¤ëŠ” ë¼ë²¨
            cell_text: ì…€ì˜ í…ìŠ¤íŠ¸
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ 80%)
        """
        # ì •ê·œí™”
        norm_cell = normalize_label(cell_text)
        norm_cell_no_colon = norm_cell.replace(':', '').strip()
        
        # ì…€ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ë¼ë²¨ì´ ì•„ë‹ ê°€ëŠ¥ì„± ë†’ìŒ (ì„¹ì…˜ ì œëª© ë“±)
        # ë‹¨, ì„œëª…ë€ì€ ê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 50ìê¹Œì§€ í—ˆìš©
        if len(norm_cell_no_colon) > 50:
            return False
        
        # ì„œëª…ë€ íŒ¨í„´ ì²´í¬ (ì˜ˆ: "ì‹ ì²­ì :    (ì¸)")
        sig_info = parse_signature_line(cell_text)
        if sig_info:
            norm_cell_no_colon = sig_info['label'].replace(':', '').strip()
        
        # ë¼ë²¨ì˜ ëª¨ë“  ë³€í˜• ê°€ì ¸ì˜¤ê¸° (ë³„ì¹­ DB í™œìš©)
        label_variants = get_label_variants(search_label)
        
        for variant in label_variants:
            norm_search = normalize_label(variant)
            norm_search_no_colon = norm_search.replace(':', '').strip()
            
            # 1. ì •í™•íˆ ì¼ì¹˜
            if norm_search == norm_cell:
                return True
            if norm_search_no_colon == norm_cell_no_colon:
                return True
            
            # 2. ì‹œì‘ ë¶€ë¶„ ì¼ì¹˜ (prefix match) - ë‹¨, ë¼ë²¨ ê¸¸ì´ê°€ ì¶©ë¶„í•´ì•¼ í•¨
            #    "ì‹ ì²­ì" â†’ "ì‹ ì²­ìê²©" ë§¤ì¹­ ë°©ì§€: ì…€ì´ ë¼ë²¨ë³´ë‹¤ í›¨ì”¬ ê¸¸ë©´ ë¬´ì‹œ
            len_ratio = len(norm_search_no_colon) / max(len(norm_cell_no_colon), 1)
            if len_ratio >= 0.7:  # ë¼ë²¨ì´ ì…€ ê¸¸ì´ì˜ 70% ì´ìƒì´ì–´ì•¼ ë§¤ì¹­
                if norm_cell.startswith(norm_search) or norm_cell_no_colon.startswith(norm_search_no_colon):
                    return True
            
            # 3. ì…€ í…ìŠ¤íŠ¸ê°€ ì§§ìœ¼ë©´ í¬í•¨ ê´€ê³„ ì²´í¬ (ë¼ë²¨ì´ ì…€ í…ìŠ¤íŠ¸ì— í¬í•¨)
            #    ë¼ë²¨ ê¸¸ì´ ë¹„ìœ¨ë„ ì²´í¬
            if len(norm_cell) <= 15 and len_ratio >= 0.7:
                if norm_search_no_colon in norm_cell_no_colon:
                    return True
        
        # 4. í¼ì§€ ë§¤ì¹­ (ìœ ì‚¬ë„) - ëŒ€í‘œ ë¼ë²¨ë§Œìœ¼ë¡œ ì²´í¬
        similarity = calc_similarity(search_label, cell_text)
        if similarity >= threshold:
            return True
        
        return False
    
    def inject_field(self, spec: FieldSpec) -> int:
        """í•„ë“œ ì£¼ì… - ì •ê·œí™” + colSpan ì¸ì‹ ì ìš©
        
        Returns: ì£¼ì…ëœ íšŸìˆ˜
        """
        injected = 0
        
        # íŠ¹ìˆ˜ê°’ ì²˜ë¦¬: AUTO_DATE â†’ í˜„ì¬ ë‚ ì§œ
        value = spec.value
        if value == "AUTO_DATE":
            value = format_current_date()
        
        # 1ë‹¨ê³„: ëª¨ë“  í…Œì´ë¸” ìˆœíšŒ
        for tbl in self.root.iter(f'{HP_NS}tbl'):
            for tr in tbl.iter(f'{HP_NS}tr'):
                row_cells = list(tr.findall(f'{HP_NS}tc'))
                
                for cell_idx, tc in enumerate(row_cells):
                    cell_text = self.get_cell_text(tc)
                    
                    # ë¼ë²¨ ë§¤ì¹­ (ì •ê·œí™” + í¼ì§€ ë§¤ì¹­)
                    if not self.match_label(spec.label, cell_text):
                        continue
                    
                    # ëª¨ë“œ ê²°ì • (ëª…ì‹œì  > ìë™)
                    if spec.mode == InjectionMode.AUTO:
                        mode = self.detect_injection_mode(spec.label, tc, row_cells, cell_idx)
                    else:
                        mode = spec.mode
                    
                    # colSpan ì •ë³´ ë¡œê¹…
                    cell_span = self.get_cell_span(tc)
                    span_info = f"(colSpan={cell_span['col']})" if cell_span['col'] > 1 else ""
                    
                    # ëª¨ë“œì— ë”°ë¼ ì£¼ì…
                    if mode == InjectionMode.NEXT_CELL:
                        # ë‹¤ìŒ ì…€ì— ì£¼ì…
                        if cell_idx + 1 < len(row_cells):
                            next_tc = row_cells[cell_idx + 1]
                            if self.inject_to_cell(next_tc, value):
                                self.log(f"âœ“ [{spec.label}] â†’ ë‹¤ìŒì…€ì— '{value[:20]}...' ì£¼ì…")
                                injected += 1
                                break
                    
                    elif mode == InjectionMode.APPEND:
                        # ë¼ë²¨ ë’¤ì— ë¶™ì´ê¸°
                        texts = list(tc.iter(f'{HP_NS}t'))
                        for t in texts:
                            if spec.label in (t.text or ''):
                                # ì½œë¡  ë’¤ì— ê°’ ì¶”ê°€
                                current = t.text or ''
                                if current.rstrip().endswith(':') or current.rstrip().endswith('ï¼š'):
                                    t.text = current.rstrip() + ' ' + value
                                else:
                                    t.text = current + ' ' + value
                                self.log(f"âœ“ [{spec.label}] â† ë’¤ì— '{value[:20]}...' ë¶™ì„")
                                injected += 1
                                break
                        if injected:
                            break
                    
                    elif mode == InjectionMode.REPLACE:
                        # ë¼ë²¨ ì „ì²´ êµì²´
                        texts = list(tc.iter(f'{HP_NS}t'))
                        if texts:
                            texts[0].text = value
                            self.log(f"âœ“ [{spec.label}] = '{value[:20]}...'ë¡œ êµì²´")
                            injected += 1
                            break
                    
                    elif mode == InjectionMode.SKIP_COLON:
                        # [ë¼ë²¨] | [:] | [ê°’] íŒ¨í„´ - 2ì¹¸ ë’¤ ì…€ì— ì£¼ì…
                        if cell_idx + 2 < len(row_cells):
                            target_tc = row_cells[cell_idx + 2]
                            if self.inject_to_cell(target_tc, value):
                                self.log(f"âœ“ [{spec.label}] â†’ ì½œë¡  ê±´ë„ˆë›°ê³  '{value[:20]}...' ì£¼ì…")
                                injected += 1
                                break
                    
                    elif mode == InjectionMode.PREPEND:
                        # [___ ë¼ë²¨] íŒ¨í„´ - ë¼ë²¨ ì• ë°‘ì¤„ ì˜ì—­ì— ì£¼ì…
                        runs = list(tc.iter(f'{HP_NS}run'))
                        norm_label = normalize_label(spec.label)
                        for i, run in enumerate(runs):
                            t = run.find(f'{HP_NS}t')
                            if t is not None and t.text and norm_label in normalize_label(t.text):
                                # ì´ run ì•ì˜ runì— ê°’ ì£¼ì…
                                if i > 0:
                                    prev_run = runs[i - 1]
                                    prev_t = prev_run.find(f'{HP_NS}t')
                                    if prev_t is not None:
                                        prev_t.text = value
                                        self.log(f"âœ“ [{spec.label}] â† ì• ë°‘ì¤„ì— '{value[:20]}...' ì£¼ì…")
                                        injected += 1
                                        break
                        if injected:
                            break
                
                if injected:
                    break
            if injected:
                break
        
        # 2ë‹¨ê³„: í…Œì´ë¸”ì—ì„œ ëª» ì°¾ìœ¼ë©´ ì¼ë°˜ paragraphì—ì„œ ê²€ìƒ‰
        if not injected:
            injected = self._inject_in_paragraph(spec, value)
        
        if not injected:
            self.log(f"âœ— [{spec.label}] ì°¾ì§€ ëª»í•¨")
        
        return injected
    
    def _inject_in_paragraph(self, spec: FieldSpec, value: str = None) -> int:
        """ì¼ë°˜ paragraph (í…Œì´ë¸” ì™¸ë¶€) ì—ì„œ ë¼ë²¨ ì°¾ì•„ ì£¼ì…
        
        íŒ¨í„´: "ë¼ë²¨ : " í˜•íƒœì—ì„œ ì½œë¡  ë’¤ì— ê°’ ì¶”ê°€
        """
        if value is None:
            value = spec.value
            if value == "AUTO_DATE":
                value = format_current_date()
        
        for t_elem in self.root.iter(f'{HP_NS}t'):
            text = t_elem.text or ''
            
            # ì •ê·œí™” í›„ ë§¤ì¹­
            if not self.match_label(spec.label, text):
                continue
            
            # ì„œëª…ë€ íŒ¨í„´ ì²´í¬
            sig_info = parse_signature_line(text)
            if sig_info:
                # ì„œëª…ë€: í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ê°’ìœ¼ë¡œ êµì²´, ì„œëª… ì ‘ë¯¸ì‚¬ ìœ ì§€
                # "ì‹ ì²­ì :     (ì¸)" â†’ "ì‹ ì²­ì : ê¹€ì² ìˆ˜ (ì¸)"
                label_part = sig_info['label']
                suffix = sig_info['suffix']
                
                # ì›ë³¸ ë¼ë²¨ í˜•íƒœ ìœ ì§€í•˜ë©´ì„œ ê°’ ì‚½ì…
                # ì •ê·œí™”ëœ ë¼ë²¨ë¡œ ì°¾ì•„ì„œ êµì²´
                new_text = re.sub(
                    r'^(.*?[:ï¼š]\s*).*?' + re.escape(suffix) + r'\s*$',
                    rf'\1{value} {suffix}',
                    text
                )
                if new_text != text:
                    t_elem.text = new_text
                    self.log(f"âœ“ [{spec.label}] â† (ì„œëª…ë€) '{value[:15]}...' ì£¼ì…")
                    return 1
            
            # ì¼ë°˜ íŒ¨í„´: ì½œë¡  ë’¤ì— ê°’ ì¶”ê°€
            current = text.rstrip()
            if current.endswith(':') or current.endswith('ï¼š'):
                t_elem.text = current + ' ' + value
                self.log(f"âœ“ [{spec.label}] â† (ë³¸ë¬¸) ë’¤ì— '{value[:20]}...' ë¶™ì„")
                return 1
            else:
                # ì½œë¡ ì´ ì—†ìœ¼ë©´ ê³µë°± ì¶”ê°€
                t_elem.text = text + ' ' + value
                self.log(f"âœ“ [{spec.label}] â† (ë³¸ë¬¸) ë’¤ì— '{value[:20]}...' ë¶™ì„")
                return 1
        
        return 0
    
    def inject_date_placeholders(self) -> int:
        """ë¬¸ì„œ ì „ì²´ì—ì„œ ë‚ ì§œ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì°¾ì•„ í˜„ì¬ ë‚ ì§œë¡œ ì±„ì›€
        
        íŒ¨í„´: "2025ë…„   ì›”   ì¼", "20  ë…„  ì›”  ì¼", "ë…„  ì›”  ì¼"
        """
        count = 0
        for t_elem in self.root.iter(f'{HP_NS}t'):
            text = t_elem.text or ''
            if is_date_placeholder(text):
                new_text = fill_date_placeholder(text)
                if new_text != text:
                    t_elem.text = new_text
                    self.log(f"âœ“ [ë‚ ì§œ] '{text.strip()[:15]}...' â†’ '{new_text}'")
                    count += 1
        return count
    
    def inject_split_date_cells(self) -> int:
        """ë¶„ë¦¬ëœ ë‚ ì§œ ì…€ íŒ¨í„´ì„ ì°¾ì•„ í˜„ì¬ ë‚ ì§œë¡œ ì±„ì›€
        
        íŒ¨í„´: [ë…„] | [ì›”] | [ì¼] - ê°ê° ë³„ë„ ì…€ë¡œ êµ¬ì„±
        í…Œì´ë¸” í–‰ì—ì„œ ì—°ì†ëœ 3ê°œ ì…€ì´ 'ë…„', 'ì›”', 'ì¼'ë¡œ ëë‚˜ë©´ ë‚ ì§œ ì£¼ì…
        """
        count = 0
        now = datetime.now()
        
        for tbl in self.root.iter(f'{HP_NS}tbl'):
            for tr in tbl.iter(f'{HP_NS}tr'):
                cells = list(tr.findall(f'{HP_NS}tc'))
                
                # ì—°ì†ëœ 3ê°œ ì…€ì—ì„œ ë…„/ì›”/ì¼ íŒ¨í„´ ì°¾ê¸°
                for i in range(len(cells) - 2):
                    cell1_text = self.get_cell_text(cells[i]).strip()
                    cell2_text = self.get_cell_text(cells[i+1]).strip()
                    cell3_text = self.get_cell_text(cells[i+2]).strip()
                    
                    # íŒ¨í„´ ë§¤ì¹­: ì…€ì´ 'ë…„', 'ì›”', 'ì¼'ë¡œ ëë‚˜ëŠ”ì§€
                    if cell1_text.endswith('ë…„') and cell2_text.endswith('ì›”') and cell3_text.endswith('ì¼'):
                        # ì´ë¯¸ ìˆ«ìê°€ ìˆëŠ”ì§€ í™•ì¸ (ë¹ˆ í”Œë ˆì´ìŠ¤í™€ë”ë§Œ ì±„ì›€)
                        year_match = re.search(r'\d{4}', cell1_text)
                        month_match = re.search(r'\d{1,2}', cell2_text)
                        day_match = re.search(r'\d{1,2}', cell3_text)
                        
                        injected_any = False
                        
                        # ë…„ ì…€ ì²˜ë¦¬
                        if not year_match or cell1_text.strip() == 'ë…„':
                            t_elems = list(cells[i].iter(f'{HP_NS}t'))
                            if t_elems:
                                t_elems[0].text = f"{now.year}ë…„"
                                injected_any = True
                        
                        # ì›” ì…€ ì²˜ë¦¬
                        if not month_match or cell2_text.strip() == 'ì›”':
                            t_elems = list(cells[i+1].iter(f'{HP_NS}t'))
                            if t_elems:
                                t_elems[0].text = f"{now.month}ì›”"
                                injected_any = True
                        
                        # ì¼ ì…€ ì²˜ë¦¬
                        if not day_match or cell3_text.strip() == 'ì¼':
                            t_elems = list(cells[i+2].iter(f'{HP_NS}t'))
                            if t_elems:
                                t_elems[0].text = f"{now.day}ì¼"
                                injected_any = True
                        
                        if injected_any:
                            self.log(f"âœ“ [ë¶„ë¦¬ë‚ ì§œ] '{cell1_text}|{cell2_text}|{cell3_text}' â†’ '{now.year}ë…„|{now.month}ì›”|{now.day}ì¼'")
                            count += 1
        
        return count
    
    def inject_signature_fields(self, config: InjectionConfig) -> int:
        """ì„œëª…ë€ íŒ¨í„´ì„ ì°¾ì•„ í•´ë‹¹ í•„ë“œ ê°’ìœ¼ë¡œ ì±„ì›€
        
        íŒ¨í„´: "ë¼ë²¨ : ã…‡ã…‡ã…‡ (ì¸)", "ë¼ë²¨ :     (ì¸)"
        """
        count = 0
        
        # í•„ë“œ ê°’ ë§µ ìƒì„± (ì •ê·œí™”ëœ ë¼ë²¨ â†’ ê°’)
        field_map = {}
        for spec in config.fields:
            norm_label = normalize_label(spec.label).replace(':', '').strip()
            field_map[norm_label] = spec.value
            
            # ë³„ì¹­ë„ ë“±ë¡
            for variant in get_label_variants(spec.label):
                norm_variant = normalize_label(variant).replace(':', '').strip()
                field_map[norm_variant] = spec.value
        
        for t_elem in self.root.iter(f'{HP_NS}t'):
            text = t_elem.text or ''
            sig_info = parse_signature_line(text)
            
            if not sig_info:
                continue
            
            # ì„œëª…ë€ ë¼ë²¨ì— í•´ë‹¹í•˜ëŠ” ê°’ ì°¾ê¸°
            label = sig_info['label'].replace(':', '').strip()
            suffix = sig_info['suffix']
            
            value = field_map.get(label)
            if not value:
                continue
            
            # ì´ë¯¸ ê°’ì´ ì±„ì›Œì ¸ ìˆìœ¼ë©´ ê±´ë„ˆëœ€
            if value in text:
                continue
            
            # ì„œëª…ë€ í˜•ì‹ìœ¼ë¡œ ê°’ ì£¼ì…
            # "ë¼ë²¨ :     ã…‡ã…‡ã…‡ (ì¸)" â†’ "ë¼ë²¨ : ê°’ (ì¸)"
            new_text = re.sub(
                r'^(.*?[:ï¼š]\s*).*?' + re.escape(suffix) + r'\s*$',
                rf'\g<1>{value} {suffix}',
                text.strip()
            )
            
            # ì›ë˜ ì• ê³µë°± ìœ ì§€
            leading_spaces = len(text) - len(text.lstrip())
            new_text = ' ' * leading_spaces + new_text
            
            if new_text != text:
                t_elem.text = new_text
                self.log(f"âœ“ [{label}] â† (ì„œëª…ë€) '{value[:15]}...' ì£¼ì…")
                count += 1
        
        return count
    
    def inject_keyword(self, keyword: str, value: str) -> int:
        """(í‚¤ì›Œë“œ) íŒ¨í„´ ì£¼ì…"""
        # regexë¡œ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
        pattern = rf'\({re.escape(keyword)}\)</hp:t></hp:run>(<hp:run[^>]*>)<hp:t>\s*</hp:t>'
        replacement = rf'({keyword})</hp:t></hp:run>\1<hp:t> {value}</hp:t>'
        
        xml_str = ET.tostring(self.root, encoding='unicode')
        new_xml, count = re.subn(pattern, replacement, xml_str)
        
        if count > 0:
            self.root = ET.fromstring(new_xml)
            self.log(f"âœ“ ({keyword}) â†’ '{value[:30]}...' ì£¼ì…")
        
        return count
    
    def process(self, config: InjectionConfig) -> str:
        """ì „ì²´ ì£¼ì… ì²˜ë¦¬"""
        print("\n" + "="*60)
        print("ğŸ”§ Smart Injector v2 - ì£¼ì… ì‹œì‘")
        print("="*60)
        
        total_injected = 0
        
        # 0. ë‚ ì§œ í”Œë ˆì´ìŠ¤í™€ë” ìë™ ì£¼ì… (Phase 2)
        date_count = self.inject_date_placeholders()
        if date_count > 0:
            print(f"\nğŸ“… ë‚ ì§œ ìë™ ì£¼ì… ({date_count}ê°œ)")
            total_injected += date_count
        
        # 0.5. ë¶„ë¦¬ëœ ë‚ ì§œ ì…€ ìë™ ì£¼ì… (ë…„|ì›”|ì¼ íŒ¨í„´)
        split_date_count = self.inject_split_date_cells()
        if split_date_count > 0:
            print(f"\nğŸ“… ë¶„ë¦¬ ë‚ ì§œ ìë™ ì£¼ì… ({split_date_count}ê°œ)")
            total_injected += split_date_count
        
        # 1. í•„ë“œ ì£¼ì… (2ë‹¨ê³„ ê·œì¹™)
        if config.fields:
            print(f"\nğŸ“ í•„ë“œ ì£¼ì… ({len(config.fields)}ê°œ):")
            for spec in config.fields:
                total_injected += self.inject_field(spec)
        
        # 1.5. ì„œëª…ë€ ìë™ ì£¼ì… (Phase 2)
        sig_count = self.inject_signature_fields(config)
        if sig_count > 0:
            print(f"\nâœï¸ ì„œëª…ë€ ìë™ ì£¼ì… ({sig_count}ê°œ)")
            total_injected += sig_count
        
        # 2. í‚¤ì›Œë“œ ì£¼ì…
        if config.keywords:
            print(f"\nğŸ”‘ í‚¤ì›Œë“œ ì£¼ì… ({len(config.keywords)}ê°œ):")
            for keyword, value in config.keywords.items():
                total_injected += self.inject_keyword(keyword, value)
        
        print(f"\nâœ… ì´ {total_injected}ê°œ ì£¼ì… ì™„ë£Œ")
        
        return ET.tostring(self.root, encoding='unicode')


def remove_linesegarray(xml_content: str) -> str:
    """linesegarray ì œê±°"""
    return re.sub(
        r'<hp:linesegarray>.*?</hp:linesegarray>',
        '',
        xml_content,
        flags=re.DOTALL
    )


# ==============================================================================
# ë¶„ì„ ê¸°ëŠ¥ (analyze ëª…ë ¹)
# ==============================================================================

# ì•Œë ¤ì§„ ë¼ë²¨ íŒ¨í„´ (ì •ê·œí™”ìš©) - ë¶„ì„ì‹œ ì‚¬ìš©
KNOWN_LABELS_FOR_ANALYZE = {
    "ê¸°ì—…ëª…": ["ê¸°ì—…ì²´ëª…", "íšŒì‚¬ëª…", "ìƒí˜¸", "ë²•ì¸ëª…", "ì—…ì²´ëª…"],
    "ëŒ€í‘œì": ["ëŒ€í‘œì´ì‚¬", "ëŒ€í‘œìëª…", "ëŒ€í‘œ", "ëŒ€í‘œìë˜ëŠ”ëŒ€í‘œì´ì‚¬"],
    "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸": ["ì‚¬ì—…ìë²ˆí˜¸", "ì‚¬ì—…ìë“±ë¡", "ë“±ë¡ë²ˆí˜¸", "ì‚¬ì—…ìë²ˆí˜¸ë˜ëŠ”ë²•ì¸ë²ˆí˜¸"],
    "ì„¤ë¦½ì¼ì": ["ì„¤ë¦½ì¼", "ì°½ì—…ì¼", "ì°½ì—…ì¼ì", "ê°œì—…ì¼"],
    "ì£¼ì†Œ": ["ì†Œì¬ì§€", "ì‚¬ì—…ì¥ì£¼ì†Œ", "ë³¸ì‚¬ì£¼ì†Œ", "íšŒì‚¬ì£¼ì†Œ"],
    "ì„±ëª…": ["ì´ë¦„", "ë‹´ë‹¹ìëª…", "ë‹´ë‹¹ì", "ì‘ì„±ì"],
    "ë¶€ì„œëª…": ["ë¶€ì„œ", "ì†Œì†ë¶€ì„œ", "ì†Œì†"],
    "ì§ìœ„": ["ì§ì±…", "ì§ê¸‰"],
    "íœ´ëŒ€í°": ["íœ´ëŒ€ì „í™”", "í•¸ë“œí°", "ëª¨ë°”ì¼", "HP"],
    "ì „í™”": ["ì „í™”ë²ˆí˜¸", "ìœ ì„ ì „í™”", "TEL"],
    "ì´ë©”ì¼": ["E-mail", "email", "ë©”ì¼", "ì´ë©”ì¼ì£¼ì†Œ"],
    "ì—°ë½ì²˜": ["ì „í™”", "ì „í™”ë²ˆí˜¸"],
    "ì‹ ì²­ê¸°ì—…ëª…": ["ì‹ ì²­ê¸°ì—…", "ì‹ ì²­ì—…ì²´ëª…"],
    "ì‹ ì²­ì": ["ì‹ ì²­ì¸", "ì‹ ì²­ìëª…"],
    "ì‹ ì²­ì¼": ["ì‹ ì²­ì¼ì", "ì ‘ìˆ˜ì¼"],
    "ê·€ì¤‘": ["ê·€í•˜", "ì•"],
}

FIELD_EXAMPLES = {
    "ê¸°ì—…ëª…": "(ì£¼)ìŠ¤ë§ˆíŠ¸í…Œí¬",
    "ëŒ€í‘œì": "í™ê¸¸ë™",
    "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸": "123-45-67890",
    "ì„¤ë¦½ì¼ì": "2018-03-15",
    "ì£¼ì†Œ": "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123",
    "ë¶€ì„œëª…": "ê¸°ìˆ ê°œë°œíŒ€",
    "ì§ìœ„": "íŒ€ì¥",
    "ì„±ëª…": "ê¹€ë‹´ë‹¹",
    "íœ´ëŒ€í°": "010-1234-5678",
    "ì „í™”": "02-555-1234",
    "ì´ë©”ì¼": "contact@company.co.kr",
    "ì—°ë½ì²˜": "02-555-1234",
    "ì‹ ì²­ê¸°ì—…ëª…": "(ê¸°ì—…ëª…ê³¼ ë™ì¼)",
    "ì‹ ì²­ì": "(ëŒ€í‘œìì™€ ë™ì¼)",
    "ì‹ ì²­ì¼": "AUTO_DATE",
    "ê·€ì¤‘": "ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ì¥ê´€",
}


@dataclass
class AnalyzedField:
    """ë¶„ì„ëœ í•„ë“œ ì •ë³´"""
    label: str
    normalized: str
    section: str
    pattern_type: str
    example: str = ""


def find_canonical_for_analyze(label: str) -> str:
    """ë¶„ì„ìš© ì •ê·œí™” ë¼ë²¨ ë³€í™˜"""
    norm = normalize_label(label)
    for canonical, variants in KNOWN_LABELS_FOR_ANALYZE.items():
        if norm == normalize_label(canonical):
            return canonical
        for v in variants:
            if norm == normalize_label(v):
                return canonical
    for canonical, variants in KNOWN_LABELS_FOR_ANALYZE.items():
        if normalize_label(canonical) in norm or norm in normalize_label(canonical):
            return canonical
    return label


def is_label_candidate(text: str) -> bool:
    """ë¼ë²¨ í›„ë³´ì¸ì§€ íŒë‹¨"""
    if not text or len(text) > 30:
        return False
    text = text.strip()
    if not text or text.isdigit():
        return False
    if text.endswith(':') or text.endswith('ï¼š'):
        return True
    norm = normalize_label(text)
    for canonical, variants in KNOWN_LABELS_FOR_ANALYZE.items():
        if norm == normalize_label(canonical):
            return True
        for v in variants:
            if norm == normalize_label(v):
                return True
    return False


def analyze_hwpx(hwpx_path: str) -> tuple:
    """HWPX íŒŒì¼ ë¶„ì„ - í•„ë“œ ì¶”ì¶œ"""
    all_fields = []
    meta = {
        "filename": Path(hwpx_path).name,
        "sections": [],
        "analyzed_at": datetime.now().strftime("%Y-%m-%d %H:%M")
    }
    
    with zipfile.ZipFile(hwpx_path, 'r') as zf:
        section_files = sorted([f for f in zf.namelist() 
                               if f.startswith('Contents/section') and f.endswith('.xml')])
        
        for section_file in section_files:
            section_name = Path(section_file).stem
            meta["sections"].append(section_name)
            
            content = zf.read(section_file).decode('utf-8')
            root = ET.fromstring(content)
            
            seen_labels = set()
            
            # í…Œì´ë¸” í•„ë“œ ì¶”ì¶œ
            for tbl_idx, tbl in enumerate(root.iter(f'{HP_NS}tbl')):
                for tr in tbl.iter(f'{HP_NS}tr'):
                    cells = list(tr.findall(f'{HP_NS}tc'))
                    for cell_idx, tc in enumerate(cells):
                        texts = [t.text for t in tc.iter(f'{HP_NS}t') if t.text]
                        cell_text = ''.join(texts).strip()
                        
                        if not is_label_candidate(cell_text):
                            continue
                        
                        # ë‹¤ìŒ ì…€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                        has_empty_next = False
                        if cell_idx + 1 < len(cells):
                            next_texts = [t.text for t in cells[cell_idx + 1].iter(f'{HP_NS}t') if t.text]
                            next_text = ''.join(next_texts).strip()
                            if not next_text:
                                has_empty_next = True
                        
                        # PREPEND íŒ¨í„´ ì²´í¬
                        runs = list(tc.iter(f'{HP_NS}run'))
                        is_prepend = False
                        if len(runs) >= 2:
                            for i, run in enumerate(runs):
                                t = run.find(f'{HP_NS}t')
                                if t is not None and t.text:
                                    if normalize_label(cell_text) in normalize_label(t.text):
                                        if i > 0:
                                            prev_t = runs[i-1].find(f'{HP_NS}t')
                                            if prev_t is not None and prev_t.text:
                                                if prev_t.text.strip() == '' and len(prev_t.text) >= 5:
                                                    is_prepend = True
                        
                        if has_empty_next or is_prepend:
                            canonical = find_canonical_for_analyze(cell_text)
                            if canonical not in seen_labels:
                                seen_labels.add(canonical)
                                all_fields.append(AnalyzedField(
                                    label=cell_text,
                                    normalized=canonical,
                                    section=section_name,
                                    pattern_type="prepend" if is_prepend else "table",
                                    example=FIELD_EXAMPLES.get(canonical, "")
                                ))
            
            # ë‚ ì§œ í•„ë“œ ì¶”ì¶œ
            date_found = False
            for t_elem in root.iter(f'{HP_NS}t'):
                text = t_elem.text or ''
                if re.search(r'\d{2,4}ë…„\s+ì›”\s+ì¼', text) and not date_found:
                    if "ì‹ ì²­ì¼" not in seen_labels:
                        seen_labels.add("ì‹ ì²­ì¼")
                        all_fields.append(AnalyzedField(
                            label="ë‚ ì§œ",
                            normalized="ì‹ ì²­ì¼",
                            section=section_name,
                            pattern_type="date",
                            example="AUTO_DATE"
                        ))
                        date_found = True
    
    # ì¤‘ë³µ ì œê±°
    seen = set()
    unique_fields = []
    for f in all_fields:
        if f.normalized not in seen:
            seen.add(f.normalized)
            unique_fields.append(f)
    
    return unique_fields, meta


def generate_yaml_template(fields: list, meta: dict) -> str:
    """ë¹ˆ YAML í…œí”Œë¦¿ ìƒì„±"""
    lines = [
        f"# {meta['filename']} - ë°ì´í„° ì…ë ¥",
        f"# ìƒì„±ì¼: {meta['analyzed_at']}",
        "#",
        "# ê° í•„ë“œì˜ valueì— ì‹¤ì œ ê°’ì„ ì…ë ¥í•˜ì„¸ìš”",
        "# ============================================================",
        "",
        "fields:"
    ]
    
    current_section = None
    for f in fields:
        if f.section != current_section:
            current_section = f.section
            lines.append(f"  # --- {current_section} ---")
        
        example_comment = f"  # ì˜ˆ: {f.example}" if f.example else ""
        lines.append(f"  - label: \"{f.normalized}\"")
        lines.append(f"    value: \"\"{example_comment}")
        lines.append("")
    
    lines.extend(["keywords: {}", "tables: {}"])
    return '\n'.join(lines)


def generate_prompt(fields: list, meta: dict) -> str:
    """ë°ì´í„° ìˆ˜ì§‘ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    lines = [
        f"# {meta['filename']} ì‘ì„±",
        "",
        "ì•„ë˜ í•­ëª©ë“¤ì˜ ê°’ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
        "í˜•ì‹: `ë¼ë²¨: ê°’`",
        "",
        "---",
        ""
    ]
    
    for f in fields:
        example = f" (ì˜ˆ: {f.example})" if f.example else ""
        lines.append(f"- **{f.normalized}**{example}")
    
    lines.extend([
        "",
        "---",
        "",
        "ì…ë ¥ ì˜ˆì‹œ:",
        "```",
        "ê¸°ì—…ëª…: (ì£¼)ABC",
        "ëŒ€í‘œì: í™ê¸¸ë™",
        "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸: 123-45-67890",
        "```"
    ])
    
    return '\n'.join(lines)


# ==============================================================================
# ì‘ë‹µ íŒŒì‹± (parse ëª…ë ¹)
# ==============================================================================

def parse_response(response_text: str) -> dict:
    """ì‚¬ìš©ì ì‘ë‹µì„ YAML êµ¬ì¡°ë¡œ íŒŒì‹±
    
    ì§€ì› í˜•ì‹:
    - "ë¼ë²¨: ê°’"
    - "ë¼ë²¨ : ê°’"
    - "ë¼ë²¨ï¼šê°’" (ì „ê° ì½œë¡ )
    """
    fields = []
    
    # ë¼ì¸ë³„ë¡œ íŒŒì‹±
    for line in response_text.strip().split('\n'):
        line = line.strip()
        if not line or line.startswith('#') or line.startswith('-'):
            continue
        
        # ì½œë¡ ìœ¼ë¡œ ë¶„ë¦¬
        match = re.match(r'^([^:ï¼š]+)[:ï¼š]\s*(.*)$', line)
        if match:
            label = match.group(1).strip()
            value = match.group(2).strip()
            
            # ë¹ˆ ê°’, "ì—†ìŒ" ë“± ì œì™¸
            if value and value.lower() not in ['ì—†ìŒ', 'í•´ë‹¹ì—†ìŒ', 'ëª¨ë¦„', '-', '']:
                # ë¼ë²¨ ì •ê·œí™”
                canonical = find_canonical_for_analyze(label)
                fields.append({
                    "label": canonical,
                    "value": value
                })
    
    return {"fields": fields, "keywords": {}, "tables": {}}


def generate_yaml_from_response(parsed: dict, meta: dict = None) -> str:
    """íŒŒì‹±ëœ ì‘ë‹µì„ YAML ë¬¸ìì—´ë¡œ ë³€í™˜"""
    lines = [
        f"# ì‘ë‹µ ë°ì´í„° - {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "#",
        "fields:"
    ]
    
    for field in parsed["fields"]:
        lines.append(f"  - label: \"{field['label']}\"")
        # ê°’ì— ë”°ì˜´í‘œê°€ í•„ìš”í•œ ê²½ìš° ì²˜ë¦¬
        value = field['value'].replace('"', '\\"')
        lines.append(f"    value: \"{value}\"")
        lines.append("")
    
    lines.extend(["keywords: {}", "tables: {}"])
    return '\n'.join(lines)


def process_hwpx(hwpx_path: str, config: InjectionConfig, output_path: str, 
                 remove_lines: bool = True) -> str:
    """HWPX íŒŒì¼ ì²˜ë¦¬"""
    
    with tempfile.TemporaryDirectory() as temp_dir:
        # ì••ì¶• í•´ì œ
        with zipfile.ZipFile(hwpx_path, 'r') as zf:
            zf.extractall(temp_dir)
        
        # section XML íŒŒì¼ë“¤ ì²˜ë¦¬
        contents_dir = os.path.join(temp_dir, 'Contents')
        for filename in os.listdir(contents_dir):
            if filename.startswith('section') and filename.endswith('.xml'):
                section_path = os.path.join(contents_dir, filename)
                
                with open(section_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ìŠ¤ë§ˆíŠ¸ ì¸ì í„°ë¡œ ì²˜ë¦¬
                injector = SmartInjector(content)
                modified = injector.process(config)
                
                # linesegarray ì œê±°
                if remove_lines:
                    modified = remove_linesegarray(modified)
                
                with open(section_path, 'w', encoding='utf-8') as f:
                    f.write(modified)
        
        # ë‹¤ì‹œ ì••ì¶•
        with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zf_out:
            for root_dir, dirs, files in os.walk(temp_dir):
                for file in files:
                    file_path = os.path.join(root_dir, file)
                    arc_name = os.path.relpath(file_path, temp_dir)
                    if file == 'mimetype':
                        zf_out.writestr(arc_name, open(file_path, 'rb').read(), 
                                       compress_type=zipfile.ZIP_STORED)
                    else:
                        zf_out.write(file_path, arc_name)
    
    print(f"\nğŸ“„ ìƒì„±: {output_path}")
    return output_path


def main():
    parser = argparse.ArgumentParser(
        description='Smart Injector v3 - í†µí•© HWPX ë°ì´í„° ì£¼ì… ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ëª…ë ¹ì–´ ì˜ˆì‹œ:
  # 1. HWPX ë¶„ì„ â†’ í”„ë¡¬í”„íŠ¸ ìƒì„±
  python smart_injector.py analyze input.hwpx -o prefix
  
  # 2. ì‚¬ìš©ì ì‘ë‹µ â†’ YAML ë³€í™˜
  python smart_injector.py parse response.txt -o fields.yaml
  
  # 3. ì£¼ì… ì‹¤í–‰
  python smart_injector.py inject input.hwpx fields.yaml -o output.hwpx
  
  # 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ (ëŒ€í™”í˜•)
  python smart_injector.py full input.hwpx -o output.hwpx
"""
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹ì–´')
    
    # === analyze ëª…ë ¹ ===
    analyze_parser = subparsers.add_parser('analyze', help='HWPX ë¶„ì„ â†’ í”„ë¡¬í”„íŠ¸ + í…œí”Œë¦¿ ìƒì„±')
    analyze_parser.add_argument('hwpx', help='ë¶„ì„í•  HWPX íŒŒì¼')
    analyze_parser.add_argument('-o', '--output', help='ì¶œë ¥ íŒŒì¼ ì ‘ë‘ì‚¬')
    analyze_parser.add_argument('--yaml-only', action='store_true', help='YAMLë§Œ ìƒì„±')
    analyze_parser.add_argument('--prompt-only', action='store_true', help='í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„±')
    
    # === parse ëª…ë ¹ ===
    parse_parser = subparsers.add_parser('parse', help='ì‚¬ìš©ì ì‘ë‹µ â†’ YAML ë³€í™˜')
    parse_parser.add_argument('response', help='ì‘ë‹µ í…ìŠ¤íŠ¸ íŒŒì¼')
    parse_parser.add_argument('-o', '--output', help='ì¶œë ¥ YAML íŒŒì¼', default='parsed_fields.yaml')
    
    # === inject ëª…ë ¹ ===
    inject_parser = subparsers.add_parser('inject', help='HWPX + YAML â†’ ì™„ì„± ë¬¸ì„œ')
    inject_parser.add_argument('hwpx', help='HWPX í…œí”Œë¦¿ íŒŒì¼')
    inject_parser.add_argument('data', help='ì£¼ì… ì„¤ì • YAML íŒŒì¼')
    inject_parser.add_argument('-o', '--output', help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    inject_parser.add_argument('--keep-lineseg', action='store_true', help='linesegarray ìœ ì§€')
    
    # === full ëª…ë ¹ ===
    full_parser = subparsers.add_parser('full', help='ì „ì²´ íŒŒì´í”„ë¼ì¸ (analyze â†’ ì…ë ¥ ëŒ€ê¸° â†’ inject)')
    full_parser.add_argument('hwpx', help='HWPX í…œí”Œë¦¿ íŒŒì¼')
    full_parser.add_argument('-o', '--output', help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    full_parser.add_argument('--response', '-r', help='ì‘ë‹µ íŒŒì¼ (ì—†ìœ¼ë©´ ëŒ€í™”í˜• ì…ë ¥)')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # === analyze ëª…ë ¹ ì²˜ë¦¬ ===
    if args.command == 'analyze':
        print(f"ğŸ“‚ ë¶„ì„ ì¤‘: {args.hwpx}")
        fields, meta = analyze_hwpx(args.hwpx)
        print(f"âœ“ {len(fields)}ê°œ í•„ë“œ ë°œê²¬")
        
        prefix = args.output if args.output else Path(args.hwpx).stem
        
        if not args.prompt_only:
            yaml_content = generate_yaml_template(fields, meta)
            yaml_path = f"{prefix}_fields.yaml"
            with open(yaml_path, 'w', encoding='utf-8') as f:
                f.write(yaml_content)
            print(f"âœ“ ì €ì¥: {yaml_path}")
        
        if not args.yaml_only:
            prompt_content = generate_prompt(fields, meta)
            prompt_path = f"{prefix}_prompt.md"
            with open(prompt_path, 'w', encoding='utf-8') as f:
                f.write(prompt_content)
            print(f"âœ“ ì €ì¥: {prompt_path}")
        
        print(f"\nğŸ“‹ ë°œê²¬ëœ í•„ë“œ:")
        for f in fields:
            print(f"  - {f.normalized} ({f.pattern_type})")
    
    # === parse ëª…ë ¹ ì²˜ë¦¬ ===
    elif args.command == 'parse':
        print(f"ğŸ“‚ íŒŒì‹± ì¤‘: {args.response}")
        
        with open(args.response, 'r', encoding='utf-8') as f:
            response_text = f.read()
        
        parsed = parse_response(response_text)
        yaml_content = generate_yaml_from_response(parsed)
        
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(yaml_content)
        
        print(f"âœ“ {len(parsed['fields'])}ê°œ í•„ë“œ íŒŒì‹±")
        print(f"âœ“ ì €ì¥: {args.output}")
        
        for field in parsed['fields']:
            print(f"  - {field['label']}: {field['value'][:20]}...")
    
    # === inject ëª…ë ¹ ì²˜ë¦¬ ===
    elif args.command == 'inject':
        config = parse_yaml_config(args.data)
        
        print(f"\nğŸ“‹ ì„¤ì • ë¡œë“œ: {args.data}")
        print(f"  - í•„ë“œ: {len(config.fields)}ê°œ")
        print(f"  - í‚¤ì›Œë“œ: {len(config.keywords)}ê°œ")
        print(f"  - í…Œì´ë¸”: {len(config.tables)}ê°œ")
        
        if args.output:
            output_path = args.output
        else:
            template_path = Path(args.hwpx)
            output_path = str(template_path.parent / f"{template_path.stem}_filled.hwpx")
        
        process_hwpx(
            args.hwpx,
            config,
            output_path,
            remove_lines=not args.keep_lineseg
        )
    
    # === full ëª…ë ¹ ì²˜ë¦¬ ===
    elif args.command == 'full':
        # 1. ë¶„ì„
        print(f"\n{'='*60}")
        print("ğŸ“‚ Step 1: HWPX ë¶„ì„")
        print('='*60)
        
        fields, meta = analyze_hwpx(args.hwpx)
        print(f"âœ“ {len(fields)}ê°œ í•„ë“œ ë°œê²¬")
        
        for f in fields:
            print(f"  - {f.normalized}")
        
        # 2. ì‘ë‹µ ìˆ˜ì§‘
        print(f"\n{'='*60}")
        print("ğŸ“ Step 2: ë°ì´í„° ì…ë ¥")
        print('='*60)
        
        if args.response:
            # íŒŒì¼ì—ì„œ ì½ê¸°
            with open(args.response, 'r', encoding='utf-8') as f:
                response_text = f.read()
            print(f"âœ“ ì‘ë‹µ íŒŒì¼ ë¡œë“œ: {args.response}")
        else:
            # ëŒ€í™”í˜• ì…ë ¥
            print("\nê° í•­ëª©ì˜ ê°’ì„ ì…ë ¥í•˜ì„¸ìš” (ë¹ˆ ê°’ì€ Enter):\n")
            responses = []
            for f in fields:
                example = f" (ì˜ˆ: {f.example})" if f.example else ""
                value = input(f"  {f.normalized}{example}: ").strip()
                if value:
                    responses.append(f"{f.normalized}: {value}")
            response_text = '\n'.join(responses)
        
        # 3. íŒŒì‹±
        parsed = parse_response(response_text)
        print(f"\nâœ“ {len(parsed['fields'])}ê°œ í•„ë“œ íŒŒì‹±ë¨")
        
        # 4. ì£¼ì…
        print(f"\n{'='*60}")
        print("ğŸ”§ Step 3: ì£¼ì… ì‹¤í–‰")
        print('='*60)
        
        # íŒŒì‹±ëœ ë°ì´í„°ë¡œ config ìƒì„±
        config = InjectionConfig(
            fields=[FieldSpec(label=f['label'], value=f['value']) for f in parsed['fields']],
            keywords={},
            tables={}
        )
        
        if args.output:
            output_path = args.output
        else:
            template_path = Path(args.hwpx)
            output_path = str(template_path.parent / f"{template_path.stem}_filled.hwpx")
        
        process_hwpx(args.hwpx, config, output_path, remove_lines=True)
        
        print(f"\n{'='*60}")
        print("âœ… ì™„ë£Œ!")
        print('='*60)


if __name__ == "__main__":
    main()
